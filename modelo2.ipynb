import time
%cls
time.sleep(0.2)
%reset -f

# Librerias
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Librerias del algoritmo de machine learning
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV


# Cargar el dataset
dataset = pd.read_csv('dataset.csv', delimiter=';', low_memory=False)

#Eliminacion de atributtos irrelevantes.
L_eliminar = ['id', 
              'title', 
              'body', 
              'amenities', 
              'currency', 
              'price_display', 
              'address', 
              'cityname', 
              'latitude', 
              'longitude', 
              'time']
dataset = dataset.drop( columns = L_eliminar)

#Eliminar registro con el precio mas alto.
precioMaximo = dataset['price'].max()
indicePrecioMaximo = dataset[dataset['price'] == precioMaximo].index
dataset = dataset.drop(indicePrecioMaximo)

# Eliminar los registros donde el atributo 'category' es 'housing/rent/apartment'
dataset = dataset[dataset['category'] == 'housing/rent/apartment']

# Eliminar los registros donde el atributo 'bedrooms' es 7 o más
dataset = dataset[dataset['bedrooms'] < 7]

# Eliminar registros con valores faltantes
dataset = dataset.dropna()

# Eliminar registros con valores WV
dataset = dataset[dataset['state'] != 'WV']

# Creacion de un modelo Random Forest
random_forest = RandomForestRegressor(n_estimators=100, random_state=42)

# Definir las variables independientes y dependiente
X = dataset[['state', 'bathrooms', 'bedrooms', 'square_feet']]
y = dataset['price']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Preprocesar los datos: codificar la variable categórica 'state' y rellenar valores faltantes
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputar valores faltantes en variables categóricas
            ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Aplicar One-Hot Encoding e ignorar categorías desconocidas
        ]), ['state']),
        ('num', SimpleImputer(strategy='mean'), ['bathrooms', 'bedrooms', 'square_feet'])  # Imputar valores faltantes en variables numéricas
    ],
    remainder='passthrough'  # Dejar las demás columnas sin cambios
)

# Definir los hiperparámetros para búsqueda
param_distributions = {
    'n_estimators': [100, 200, 300, 400, 500],
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2'],
    'bootstrap': [True, False]
}

# Configurar la búsqueda de hiperparámetros
random_search = RandomizedSearchCV(
    estimator=random_forest,
    param_distributions=param_distributions,
    n_iter=100,  # Número de combinaciones a probar
    cv=3,  # Número de divisiones para validación cruzada
    verbose=2,  # Nivel de detalle de salida
    random_state=42,
    n_jobs=-1  # Usar todos los procesadores disponibles
)


# Crear el pipeline con preprocesamiento y modelo de Random Forest
pipeline_rf = Pipeline(steps=[
    ('preprocessor', preprocessor),  # Aplicar el preprocesador
    ('regressor', random_forest)  # Aplicar el modelo de Random Forest
])

# Entrenar el modelo
pipeline_rf.fit(X_train, y_train)

# Hacer predicciones en los datos de prueba
y_pred_rf = pipeline_rf.predict(X_test)

# Mostrar los mejores hiperparámetros encontrados
print(f'Mejores hiperparámetros: {random_search.get_params}')

# Calcular el error cuadrático medio (MSE)
mse_rf = mean_squared_error(y_test, y_pred_rf)
print(f'Error cuadrático medio (Random Forest): {mse_rf}')

# Calcular el coeficiente de determinación (R^2)
r2_rf = r2_score(y_test, y_pred_rf)
print(f'Coeficiente de determinación (R^2) (Random Forest): {r2_rf}')












































































